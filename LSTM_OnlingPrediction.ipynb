{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Online Prediction\n",
    "Do online testing once in a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "from math import sqrt, floor\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from indicator import *\n",
    "from keras.layers import AlphaDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for each stocks and label them as winning/losing for each period\n",
    "def preposessing(close,volume,high,low,lags):\n",
    "    # number of tickers\n",
    "    N = close.shape[1]\n",
    "    # Initialize 3 list to store dataframe\n",
    "    dflist = []\n",
    "    FutureReturnlist = []\n",
    "    outputlist = []\n",
    "\n",
    "    # Use for loop to create a dataframe for each stock\n",
    "    for i in range(N):\n",
    "        closei = close.iloc[:,i].values\n",
    "        volumei = volume.iloc[:,i].values\n",
    "        highi = high.iloc[:,i].values\n",
    "        lowi = low.iloc[:,i].values\n",
    "        df = pd.DataFrame(data={'Close':closei,'Volume':volumei,'High':highi,'Low':lowi},index=close.index)\n",
    "        # Current Return\n",
    "        #df['Return'] = df['Close'] / df['Close'].shift(lags) - 1\n",
    "        # Future Return only for classify stocks into winning and losing. Need to drop it after classification\n",
    "        df['FutureReturn'] =   df['Close'].shift(-lags) /df['Close']  - 1  # t's return = t+lags / t  - 1\n",
    "        FutureReturnlist.append(df['FutureReturn'])\n",
    "        dflist.append(df)\n",
    "\n",
    "    # Concatenate all stocks returns and find the median for each date\n",
    "    Return = pd.concat(FutureReturnlist,axis=1)\n",
    "    Return['median'] = Return.quantile(q=0.5,axis=1)\n",
    "    \n",
    "    # Add other stock's median return as features\n",
    "    currentReturn = close/close.shift(1)-1\n",
    "    currentReturn.columns = [colName + ' Return' for colName in close.columns]\n",
    "    currentReturn['Median Return'] = currentReturn.quantile(q=0.5,axis=1)\n",
    "    for i in range(len(dflist)):\n",
    "        dflist[i] = pd.concat([dflist[i], currentReturn], axis=1)\n",
    "\n",
    "    # Classify stocks as 1 if its return > median\n",
    "    for i in range(N):\n",
    "        df = dflist[i]\n",
    "        df['Y'] = np.where(df['FutureReturn'] > Return['median'],pd.Series(1),pd.Series(0))\n",
    "        df.dropna(inplace = True)\n",
    "        df.drop(columns='FutureReturn', inplace=True)\n",
    "        outputlist.append(df)\n",
    "\n",
    "    return outputlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate technical indicators\n",
    "def indicator(df):\n",
    "    df= moving_average(df,20)\n",
    "    df= exponential_moving_average(df,40)\n",
    "    df= stochastic_oscillator_d(df,3)\n",
    "    df = macd(df, 12, 26)\n",
    "    df = on_balance_volume(df, 30)\n",
    "    df = relative_strength_index(df, 6)\n",
    "    df = commodity_channel_index(df, 14)\n",
    "    df = average_directional_movement_index(df, 14, 6)\n",
    "    df = trix(df, 12)\n",
    "    df = standard_deviation(df, 20)\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop('High', axis=1, inplace=True)\n",
    "    df.drop('Low', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning for LSTM\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM model and predict the state of last period \n",
    "def trainLSTM(stocks, Ys, date, train_ratio, window=40, max_epoch=50, lstm_node = 50, LSTMs = None, epoch_validation = True, yLookback = 20):\n",
    "     \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    if LSTMs is None:\n",
    "        LSTMs = []\n",
    "    \n",
    "    performance_record = []\n",
    "    normalizers = []\n",
    "    optimal_epoch = []\n",
    "    trainPredict = None\n",
    "    validationPredict = None\n",
    "    testPredict = None\n",
    "\n",
    "    \n",
    "    for stock_idx in range(len(stocks)):\n",
    "        stock = stocks[stock_idx]\n",
    "        print('Training LSTM: '+str(stock_idx)+'/'+str(len(stocks)))\n",
    "        \n",
    "        values = stock.values.astype('float32')\n",
    "        valuesY = Ys[stock_idx].values.astype('float32')\n",
    "        n_features = values.shape[1]\n",
    "        \n",
    "        # normalize features\n",
    "        n_train_days = floor(values.shape[0]*train_ratio)\n",
    "        train_values = values[:n_train_days,:]\n",
    "        validation_values = values[n_train_days:, :]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_train = scaler.fit_transform(train_values)\n",
    "        normalizers.append(scaled_train)\n",
    "        scaled_validation = scaler.transform(validation_values)\n",
    "        scaled = np.append(scaled_train, scaled_validation, axis=0)\n",
    "             \n",
    "        # get lagged features\n",
    "        reframed = series_to_supervised(scaled, window-1, 1)\n",
    "        \n",
    "        # split into train, validation and test sets, input and outputs\n",
    "        values = reframed.values\n",
    "\n",
    "        training_len = n_train_days - (window - 1)\n",
    "        \n",
    "        train_date = date[(window-1):(window-1+training_len)]\n",
    "        validation_date = date[(window-1+training_len):-yLookback]\n",
    "        test_date = date[-1]\n",
    "\n",
    "        train_y = valuesY[(window-1):(window-1+training_len)]\n",
    "        validation_y = valuesY[(window-1+training_len):-yLookback]\n",
    "        test_y = valuesY[-1]\n",
    "\n",
    "        train_X = values[:training_len, :]\n",
    "        validation_X = values[training_len:-yLookback,:]\n",
    "        test_X = values[-1,:]\n",
    "        \n",
    "        # reshape input to be 3D [samples, timesteps, features]\n",
    "        train_X = train_X.reshape((train_X.shape[0], window, n_features))\n",
    "        validation_X = validation_X.reshape((validation_X.shape[0], window, n_features))\n",
    "        test_X = test_X.reshape((1, window, n_features))\n",
    "        \n",
    "        # construct network\n",
    "        model_weights = []\n",
    "        history_record = []\n",
    "        \n",
    "        if(len(LSTMs)<stock_idx+1):\n",
    "            # design network\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(lstm_node, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "            #model.add(AlphaDropout(0.1))\n",
    "            #model.add(Dense(20, activation='selu', kernel_initializer='lecun_normal'))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "            LSTMs.append(model)\n",
    "        else:\n",
    "            model = LSTMs[stock_idx]\n",
    "            \n",
    "        # fit network\n",
    "        if epoch_validation:\n",
    "            for i in range(max_epoch):\n",
    "                history = model.fit(train_X, train_y, epochs=1, validation_data=(validation_X, validation_y), verbose=0, shuffle=False)\n",
    "                history_record.append(history.history)\n",
    "                model_weights.append(model.get_weights())\n",
    "\n",
    "            val_loss = [dic['val_loss'][0] for dic in history_record]\n",
    "            optimal_epoch.append(np.argmin(val_loss) + 1)\n",
    "            model.set_weights(model_weights[np.argmin(val_loss)])\n",
    "            performance_record.append(history_record[np.argmin(val_loss)])\n",
    "\n",
    "            model.fit(validation_X, validation_y, verbose=0, shuffle=False, epochs=optimal_epoch[-1])\n",
    "            \n",
    "        else:\n",
    "            train_X = np.append(train_X, validation_X, axis=0)\n",
    "            train_y = np.append(train_y, validation_y, axis=0)\n",
    "            model.fit(train_X, train_y, verbose=0, shuffle=False, epochs=max_epoch)\n",
    "        \n",
    "        LSTMs[stock_idx] = model\n",
    "        \n",
    "        # make a prediction\n",
    "        if testPredict is None:\n",
    "            #trainPredict = DataFrame({'Date':train_date, symbols[stock_idx]:np.squeeze(model.predict(train_X))}).set_index('Date')\n",
    "            #validationPredict= DataFrame({'Date':validation_date, symbols[stock_idx]:np.squeeze(model.predict(validation_X))}).set_index('Date')\n",
    "            testPredict= DataFrame({symbols[stock_idx]:np.squeeze(model.predict(test_X))}, index=pd.Index([test_date], name='Date'))\n",
    "        else:\n",
    "            #trainPredict[symbols[stock_idx]] = np.squeeze(model.predict(train_X))\n",
    "            #validationPredict[symbols[stock_idx]] = np.squeeze(model.predict(validation_X))\n",
    "            testPredict[symbols[stock_idx]] = np.squeeze(model.predict(test_X))\n",
    "        \n",
    "    \n",
    "    return LSTMs, optimal_epoch, performance_record, trainPredict, validationPredict, testPredict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate its perfomance matrix\n",
    "def Performancematrix(portfolio,rf):\n",
    "    portfolio['Cum_Wealth'] = pd.Series(1+portfolio.Return).cumprod()\n",
    "    portfolio['Cum_Return'] = portfolio['Cum_Wealth'] - 1\n",
    "    Sharpe = round((np.mean(portfolio.Return) - rf ) / (np.std(portfolio.Return)) * sqrt(12) , 2)\n",
    "    drawdown = round (portfolio['Cum_Wealth'] - portfolio['Cum_Wealth'].cummax(), 2)\n",
    "    max_drawdown = drawdown.min()\n",
    "    Cumulative_Return = round(portfolio['Cum_Return'].values[-1],2)\n",
    "    return Sharpe,max_drawdown,Cumulative_Return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "close = pd.read_csv('price.csv',index_col=0)\n",
    "volume = pd.read_csv('volume.csv',index_col=0)\n",
    "high = pd.read_csv('high.csv',index_col=0)\n",
    "low = pd.read_csv('low.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Basic Parameters\n",
    "holding = 20\n",
    "rf = 0.02/12\n",
    "n_stocks = 10\n",
    "n_block_len = 200\n",
    "training_ratio = 0.8\n",
    "lookback_window = 20\n",
    "first_train_max_epoch = 50\n",
    "online_train_max_epoch = 50\n",
    "n_LSTM_node = 50\n",
    "block_start_idx = 300  # Set the start point to train\n",
    "testingperiod = 95 # How many periods you want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label and return\n",
    "stocks = []\n",
    "Ys = []\n",
    "symbols = list(close.columns)\n",
    "\n",
    "dataset = preposessing(close,volume,high,low,holding)\n",
    "date = dataset[0].index  # Store the calendar date\n",
    "for i in range(len(dataset)):\n",
    "    stock = indicator(dataset[i].reset_index(drop=True))\n",
    "    stocks.append(stock.drop(['Y','Close','Volume','MA_20','EMA_40', 'OBV_30'], axis=1))\n",
    "    Ys.append(stock['Y'])\n",
    "date = date[stocks[0].index[0]:]  # Log out the corresponding calendar date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Return of the following holding period\n",
    "stockreturns = pd.DataFrame()\n",
    "lagged = holding\n",
    "for i in range(len(symbols)):\n",
    "    ticker = symbols[i]\n",
    "    stockreturns[ticker] = close[ticker].shift(-lagged) / close[ticker]   - 1\n",
    "stockreturns.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the first block of data\n",
    "predictedResult = []\n",
    "\n",
    "Xblock = [df.iloc[block_start_idx:(block_start_idx+n_block_len),:] for df in stocks]\n",
    "Yblock = [df.iloc[block_start_idx:(block_start_idx+n_block_len)] for df in Ys]\n",
    "dateBlock = date[block_start_idx:(block_start_idx + n_block_len)]\n",
    "\n",
    "# Initialize and train LSTMs\n",
    "LSTMs, optimal_epoch, performance_record, trainPredict, validationPredict, testPredict = trainLSTM(\n",
    "    Xblock, Yblock, dateBlock, training_ratio, window=lookback_window, max_epoch=first_train_max_epoch, \n",
    "    lstm_node = n_LSTM_node, LSTMs = None)\n",
    "\n",
    "predictedResult.append(testPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start online training and get the prediction \n",
    "start_idx = block_start_idx +  holding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (testingperiod):\n",
    "    #Get the next block\n",
    "    block_start_idx = start_idx + holding * i\n",
    "    Xblock = [ df.iloc[block_start_idx:(block_start_idx+n_block_len),:] for df in stocks]\n",
    "    Yblock = [ df.iloc[block_start_idx:(block_start_idx+n_block_len)] for df in Ys]\n",
    "    dateBlock = date[block_start_idx:(block_start_idx + n_block_len)]\n",
    "    print('Training: ' + str(dateBlock[-1]))\n",
    "    # Training LSTMs\n",
    "    LSTMs, optimal_epoch, performance_record, trainPredict, validationPredict, testPredict = trainLSTM(\n",
    "        Xblock, Yblock, dateBlock, training_ratio, window=lookback_window, max_epoch=online_train_max_epoch, \n",
    "        lstm_node = n_LSTM_node, LSTMs = LSTMs)\n",
    "    # Construct a portfolio based on the predicted results\n",
    "    predictedResult.append(testPredict)\n",
    "\n",
    "# Store all predict result into a dataframe for portfolio construction\n",
    "predictedResult = pd.concat(predictedResult,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedResult.to_csv('predicted.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
